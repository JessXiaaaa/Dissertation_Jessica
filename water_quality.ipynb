{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare the measurement values of a certain parameter at different sites near the MINEWATER site in the same year and month\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\distancesS71567.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Filter out the data for the year 2018 and records where parameter_name is 'pH'\n",
    "df_filtered = df[(df['sampling_year'] == 2018) & (df['parameter_name'] == 'pH')]\n",
    "\n",
    "# Convert the sampling_datetime column to date format and extract year and month\n",
    "df_filtered['sampling_datetime'] = pd.to_datetime(df_filtered['sampling_datetime'])\n",
    "df_filtered['month'] = df_filtered['sampling_datetime'].dt.to_period('M')\n",
    "\n",
    "# Group by month and calculate the average measurement value for each station each month\n",
    "grouped = df_filtered.groupby('month')[['station_number', 'sample_value', 'distance']]\n",
    "\n",
    "# Sort the data for each month by distance\n",
    "# Use the apply method of the groupby object, ensuring that the return is a DataFrame\n",
    "monthly_data = grouped.apply(lambda x: x.sort_values(by='distance')).reset_index()\n",
    "\n",
    "# Get the grouping key, which is each month\n",
    "months = monthly_data['month'].unique()\n",
    "\n",
    "# Generate a bar chart for each month\n",
    "for month in months:\n",
    "    # Filter the data for the current month\n",
    "    month_data = monthly_data[monthly_data['month'] == month]\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Ensure month_data is a DataFrame and access data using column names\n",
    "    plt.bar(month_data['station_number'], month_data['sample_value'], color='blue')\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    plt.title(f'Monthly Solids, Suspended at 105 C - {month}')\n",
    "    plt.xlabel('Station Number')\n",
    "    plt.ylabel('Sample Value (Solids, Suspended at 105 C)')\n",
    "\n",
    "    # Rotate x-axis labels to prevent overlap\n",
    "    # plt.xticks(rotation=45, labels=month_data['station_number'].astype(str))\n",
    "\n",
    "    # Save the figure\n",
    "    output_filename = f'D:\\\\PycharmProjects\\\\minewaters_new\\\\pic\\\\Solids, Suspended at 105 C_{month.strftime(\"%Y-%m\")}.png'\n",
    "    plt.savefig(output_filename)\n",
    "    print(f'Saved figure to {output_filename}')\n",
    "\n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "print(\"Bar charts for each month have been generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a map of MINEWATER stations and their 10 nearest stations for each year\n",
    "import os\n",
    "import pandas as pd\n",
    "import folium\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Define data directory and target year\n",
    "data_dir = r'D:\\PycharmProjects\\minewaters_new\\CleanYear'\n",
    "year = 2022\n",
    "\n",
    "# Create a coordinate transformer\n",
    "transformer = Transformer.from_crs('epsg:27700', 'epsg:4326', always_xy=True)\n",
    "\n",
    "# Create a function to convert coordinates\n",
    "def convert_coordinates(easting, northing):\n",
    "    lon, lat = transformer.transform(easting, northing)\n",
    "    return lon, lat\n",
    "\n",
    "# Define a list of available colors\n",
    "folium_colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred',\n",
    "                 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'darkpurple', 'white',\n",
    "                 'pink', 'lightblue', 'lightgreen', 'gray', 'black', 'lightgray']\n",
    "\n",
    "# Initialize the map and set the initial center\n",
    "map_center = [53.0, -2.0]  # Set a suitable center point\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = os.path.join(data_dir, f'{year} Water Quality Archive Cleaned.csv')\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found: {file_path}\")\n",
    "else:\n",
    "    data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    data = data.drop_duplicates(subset='station_number', keep='first')\n",
    "\n",
    "    data[['longitude', 'latitude']] = data.apply(lambda row: convert_coordinates(row['easting'], row['northing']), axis=1, result_type='expand')\n",
    "\n",
    "    # Filter for stations of type 'MINEWATER'\n",
    "    minewaters_data = data[data['station_type'] == 'MINEWATER']\n",
    "    unique_stations = data.drop_duplicates(subset=['station_number'])\n",
    "    coordinates = unique_stations[['longitude', 'latitude']].values\n",
    "\n",
    "    # Use NearestNeighbors to find the nearest stations\n",
    "    n_neighbors = min(11, len(unique_stations))\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(coordinates)\n",
    "\n",
    "    # Create a FeatureGroup and set it to not display by default\n",
    "    fg = folium.FeatureGroup(name=str(year), show=False)\n",
    "\n",
    "    # Iterate through each 'MINEWATER' station\n",
    "    for idx, (row_idx, row) in enumerate(minewaters_data.iterrows()):\n",
    "        station_id = row['station_number']\n",
    "\n",
    "        station_index = unique_stations[unique_stations['station_number'] == station_id].index[0]\n",
    "\n",
    "        indices = nbrs.kneighbors([row[['longitude', 'latitude']].values], return_distance=False)\n",
    "\n",
    "        # Get neighbor stations\n",
    "        neighbor_indices = indices.flatten()[1:min(n_neighbors, len(indices.flatten()))]\n",
    "        neighbor_data = unique_stations.iloc[neighbor_indices].copy()\n",
    "        neighbor_station_numbers = neighbor_data['station_number'].tolist()\n",
    "        neighbor_station_numbers_str = \", \".join(map(str, neighbor_station_numbers))\n",
    "\n",
    "        # Use the colors provided by Folium\n",
    "        color = folium_colors[idx % len(folium_colors)]\n",
    "\n",
    "        # Add the 'MINEWATER' station to the FeatureGroup\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=folium.Popup(f'MINEWATER Station {station_id} ({year})<br>Neighbors: {neighbor_station_numbers_str}', parse_html=True),\n",
    "            icon=folium.Icon(color=color, icon='star')\n",
    "        ).add_to(fg)\n",
    "\n",
    "        # Draw neighbor stations\n",
    "        for _, neighbor_row in neighbor_data.iterrows():\n",
    "            neighbor_station_id = neighbor_row['station_number']\n",
    "            folium.CircleMarker(\n",
    "                location=[neighbor_row['latitude'], neighbor_row['longitude']],\n",
    "                radius=5,\n",
    "                popup=folium.Popup(f'Station {neighbor_station_id} ({year})', parse_html=True),\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.6\n",
    "            ).add_to(fg)\n",
    "\n",
    "    # Add the FeatureGroup to the map\n",
    "    fg.add_to(m)\n",
    "\n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    # Save the map to a folder\n",
    "    output_folder = os.path.join(data_dir, 'MINEWATER_Maps')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    map_path = os.path.join(output_folder, 'minewater_stations_map.html')\n",
    "    m.save(map_path)\n",
    "\n",
    "    print(f\"Interactive map saved successfully in folder: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the years each MINEWATER station appeared from 2000 to 2023\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Result storage dictionary, key is station_number, value is a list of years appeared\n",
    "station_years = {}\n",
    "\n",
    "# Iterate from 2000 to 2023\n",
    "for year in range(2000, 2024):\n",
    "    filename = f'D:\\\\PycharmProjects\\\\minewaters_new\\\\convert\\\\{year} Water Quality Archive Unified.csv'\n",
    "    if os.path.exists(filename):  # Check if the file exists\n",
    "        df = pd.read_csv(filename, low_memory=False)\n",
    "        # Filter MINEWATER stations\n",
    "        minewater_df = df[df['station_type'] == 'MINEWATER']\n",
    "\n",
    "        # Iterate through the filtered DataFrame and update station appearance years\n",
    "        for _, row in minewater_df.iterrows():\n",
    "            station_number = row['station_number']\n",
    "            if station_number in station_years:\n",
    "                if year not in station_years[station_number]:\n",
    "                    station_years[station_number].append(year)\n",
    "            else:\n",
    "                station_years[station_number] = [year]\n",
    "\n",
    "# Convert the result storage dictionary to a DataFrame\n",
    "result_df = pd.DataFrame(list(station_years.items()), columns=['station_number', 'years'])\n",
    "\n",
    "# Output the results to a CSV file\n",
    "output_file = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\MINEWATER_Station_Occurrences_Years.csv'\n",
    "result_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"The occurrences and years of each MINEWATER station have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all 10 closest stations to a specific MINEWATER station from 2000 to 2024\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Define a function to calculate the Euclidean distance between two points\n",
    "def calculate_distance(easting1, northing1, easting2, northing2):\n",
    "    return euclidean((easting1, northing1), (easting2, northing2))\n",
    "\n",
    "# Initialize an empty DataFrame to store the final results\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "# Iterate through files from 2000 to 2023\n",
    "for year in range(2000, 2024):\n",
    "    filename = f'D:\\\\PycharmProjects\\\\minewaters_new\\\\convert\\\\{year} Water Quality Archive Unified.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filename, low_memory=False)\n",
    "\n",
    "    # Remove duplicates based on station_name, keeping the first occurrence\n",
    "    df_unique = df.drop_duplicates(subset='station_name', keep='first')\n",
    "\n",
    "    # Filter for the station_number 'S71567'\n",
    "    S71567_df = df_unique[df_unique['station_number'] == 'S71567']\n",
    "\n",
    "    if not S71567_df.empty:\n",
    "        # Get the coordinates of the S71567 station\n",
    "        S71567_row = S71567_df.iloc[0]\n",
    "        S71567_easting, S71567_northing = S71567_row['easting'], S71567_row['northing']\n",
    "\n",
    "        # Calculate the distance of each station in df_unique to the S71567 station, and add it to a new column\n",
    "        df_unique['distance_to_S71567'] = df_unique.apply(\n",
    "            lambda row: calculate_distance(row['easting'], row['northing'], S71567_easting, S71567_northing), axis=1\n",
    "        )\n",
    "\n",
    "        # Sort by distance and select the index of S71567 station and its nearest 10 stations\n",
    "        sorted_df = df_unique.sort_values('distance_to_S71567')\n",
    "        nearest_indices = sorted_df.index[:11]  # Includes S71567 station and the nearest 10 stations\n",
    "\n",
    "        # Use the station_numbers in the list as indexes to get all corresponding rows in df\n",
    "        for index in nearest_indices:\n",
    "            station_number = df_unique.loc[index, 'station_number']\n",
    "            # Find all rows in the original df with the same station_number\n",
    "            same_station_number_rows = df[df['station_number'] == station_number]\n",
    "            final_result = pd.concat([final_result, same_station_number_rows], ignore_index=True)\n",
    "\n",
    "    # If the current year's file does not have the S71567 station, print a message\n",
    "    else:\n",
    "        print(f\"Year {year}: No station with station_number 'S71567' found.\")\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_filename = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\Closest_Stations_to_S71567.csv'\n",
    "final_result.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"The result has been written to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter line chart visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\NEATH.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the range of years to analyze and the parameter\n",
    "years_to_include = range(2000, 2024)  \n",
    "parameter_to_plot = 'Magnesium,Dissolved'  \n",
    "\n",
    "# Filter data for the specified years and parameter\n",
    "filtered_df = df[(df['sampling_year'].isin(years_to_include)) & (df['parameter_name'] == parameter_to_plot)]\n",
    "\n",
    "# Ensure sampling_datetime is in datetime format\n",
    "filtered_df['sampling_datetime'] = pd.to_datetime(filtered_df['sampling_datetime'], errors='coerce')\n",
    "\n",
    "# Remove rows with conversion errors\n",
    "filtered_df = filtered_df.dropna(subset=['sampling_datetime'])\n",
    "\n",
    "# Extract year and month, and create a complete time column\n",
    "filtered_df['YearMonth'] = filtered_df['sampling_datetime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Group by station, year, and month, and calculate the monthly average\n",
    "monthly_avg = filtered_df.groupby(['station_number', 'station_type', 'YearMonth'])['sample_value'].mean().reset_index()\n",
    "\n",
    "# Convert YearMonth to datetime format to ensure correct sorting\n",
    "monthly_avg['YearMonth'] = pd.to_datetime(monthly_avg['YearMonth'], format='%Y-%m')\n",
    "\n",
    "# Sort by time\n",
    "monthly_avg = monthly_avg.sort_values(by='YearMonth')\n",
    "\n",
    "# Define colors for each station\n",
    "station_colors = {\n",
    "    'S78396': 'blue',\n",
    "    'S10003': 'green',\n",
    "    'S10004': 'red',\n",
    "    'S78410': 'purple'\n",
    "    # Add more colors according to your actual station names\n",
    "}\n",
    "\n",
    "# Plot the line chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the line chart for each station\n",
    "for station in monthly_avg['station_number'].unique():\n",
    "    station_data = monthly_avg[monthly_avg['station_number'] == station]\n",
    "    station_type = station_data['station_type'].iloc[0]  \n",
    "    color = station_colors.get(station, 'black')  \n",
    "    plt.plot(station_data['YearMonth'], station_data['sample_value'], marker='o', color=color, label=f'Station {station} ({station_type})')\n",
    "\n",
    "# Add legend, title, and labels\n",
    "plt.legend()\n",
    "plt.title(f'Monthly Average of {parameter_to_plot} from {years_to_include.start} to {years_to_include.stop-1}')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Average Sample Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw heatmaps for various parameters\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "file_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\distancesS71567.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Data transformation\n",
    "# Bin the distance into 5 categories\n",
    "data['distance_bin'] = pd.qcut(data['distance'], q=5, labels=['Near', 'Close', 'Mid', 'Far', 'Distant'])\n",
    "\n",
    "# Calculate the average measurement value for each parameter in each distance bin\n",
    "average_values = data.groupby(['distance_bin', 'parameter_name'])['sample_value'].mean().reset_index()\n",
    "\n",
    "# Step 3: Draw the heatmap\n",
    "# Rearrange the data using pivot\n",
    "pivot_table = average_values.pivot(index='parameter_name', columns='distance_bin', values='sample_value')\n",
    "\n",
    "# Draw the heatmap\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.heatmap(pivot_table,\n",
    "            annot=True,  \n",
    "            fmt=\".2f\",  \n",
    "            cmap='coolwarm',  \n",
    "            cbar=True)  \n",
    "\n",
    "# Adjust the heatmap\n",
    "plt.title('Heatmap of Average Sample Values by Distance Bins and Parameters')\n",
    "plt.xlabel('Distance Bin')\n",
    "plt.ylabel('Parameter Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a map for specified stations\n",
    "import pandas as pd\n",
    "import folium\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Create a coordinate transformer\n",
    "transformer = Transformer.from_crs('epsg:27700', 'epsg:4326', always_xy=True)\n",
    "\n",
    "# Function to convert coordinates\n",
    "def convert_coordinates(easting, northing):\n",
    "    lon, lat = transformer.transform(easting, northing)\n",
    "    return lon, lat\n",
    "\n",
    "# Define data directory and target year\n",
    "data_dir = r'D:\\PycharmProjects\\minewaters_new\\CleanYear'\n",
    "year = 2022\n",
    "\n",
    "# Specify the station numbers to output\n",
    "specific_stations = ['S10003', 'S10004', 'S10008', 'S10009', 'S71586', 'S71625', 'S71660', 'S71661', 'S71662', 'S71663',\n",
    "                     'S71730', 'S76600', 'S71571', 'S10010', 'S51343', 'S78415',  'S71539', 'S78410', 'S19142','S78396']\n",
    "\n",
    "folium_colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred',\n",
    "                 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'darkpurple',\n",
    "                 'pink', 'lightblue',  'black']\n",
    "\n",
    "# Initialize the map and set the initial center\n",
    "map_center = [53.0, -2.0]  # Set a suitable center point\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\total_station_info.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found: {file_path}\")\n",
    "else:\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Remove duplicate stations with the same 'station_number'\n",
    "    data = data.drop_duplicates(subset='station_number', keep='first')\n",
    "\n",
    "    # Apply coordinate transformation to the data\n",
    "    data[['longitude', 'latitude']] = data.apply(lambda row: convert_coordinates(row['easting'], row['northing']),\n",
    "                                                 axis=1, result_type='expand')\n",
    "\n",
    "    # Filter only the specified stations\n",
    "    filtered_data = data[data['station_number'].isin(specific_stations)]\n",
    "\n",
    "    # Create a FeatureGroup and set it to not display by default\n",
    "    fg = folium.FeatureGroup(name=str(year), show=False)\n",
    "\n",
    "    # Iterate through each station\n",
    "    for idx, (row_idx, row) in enumerate(filtered_data.iterrows()):\n",
    "        station_id = row['station_number']\n",
    "\n",
    "        # Use colors provided by folium\n",
    "        color = folium_colors[idx % len(folium_colors)]\n",
    "\n",
    "        # Add circle markers\n",
    "        folium.CircleMarker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            radius=5,  # Adjust the radius of the circle\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=f'Station {station_id}',  # Tooltip displays the station number\n",
    "        ).add_to(fg)\n",
    "\n",
    "        # Add the station number, adjusting position to avoid overlap\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            icon=folium.DivIcon(\n",
    "                html=f'<div style=\"font-size: 12px; color: {color}; font-weight: bold; transform: translate(-50%, -50%);\">{station_id}</div>'\n",
    "            ),\n",
    "            icon_anchor=(0, 0)  # Adjust the anchor point of the icon\n",
    "        ).add_to(fg)\n",
    "\n",
    "    # Add the FeatureGroup to the map\n",
    "    fg.add_to(m)\n",
    "\n",
    "    # Load Neath River data (GeoJSON or Shapefile)\n",
    "    neath_river_data_path = r'D:\\PycharmProjects\\minewaters_new\\export.geojson'\n",
    "    neath_river = gpd.read_file(neath_river_data_path)\n",
    "\n",
    "    # Draw Neath River on the map\n",
    "    for _, row in neath_river.iterrows():\n",
    "        geometry = shape(row['geometry'])\n",
    "        # Convert to longitude and latitude\n",
    "        if geometry.geom_type == 'Polygon':\n",
    "            coords = list(geometry.exterior.coords)\n",
    "        elif geometry.geom_type == 'LineString':\n",
    "            coords = list(geometry.coords)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        folium.PolyLine(locations=[(lat, lon) for lon, lat in coords],\n",
    "                        color='blue',\n",
    "                        weight=2.5,\n",
    "                        opacity=1).add_to(m)\n",
    "\n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    # Save the map to a folder\n",
    "    output_folder = os.path.join(data_dir, 'MINEWATER_Maps')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    map_path = os.path.join(output_folder, 'NEATH2.html')\n",
    "    m.save(map_path)\n",
    "\n",
    "    print(f\"Interactive map saved successfully in folder: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new dataset categorized by local_authority\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the CSV file\n",
    "summary_csv_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\unique_values_summary.csv'\n",
    "archive_folder_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\convert'\n",
    "\n",
    "# Read the summary CSV file\n",
    "summary_df = pd.read_csv(summary_csv_path)\n",
    "\n",
    "# Create a dictionary to store data corresponding to each local_authority\n",
    "la_data_dict = {}\n",
    "\n",
    "# Iterate over the years from 2000 to 2023\n",
    "for year in range(2000, 2024):\n",
    "    # Construct the full path for the archive file\n",
    "    archive_csv_path = os.path.join(archive_folder_path, f'{year} Water Quality Archive Unified.csv')\n",
    "\n",
    "    # Read the archive file\n",
    "    if os.path.exists(archive_csv_path):\n",
    "        archive_df = pd.read_csv(archive_csv_path, low_memory=False)\n",
    "\n",
    "        # Iterate over local_authority in the summary CSV\n",
    "        for la in summary_df['local_authority'].unique():\n",
    "            # Filter the archive file's data based on local_authority\n",
    "            filtered_df = archive_df[archive_df['local_authority'] == la]\n",
    "\n",
    "            # If the filtered data is not empty, add it to the corresponding local_authority key in the dictionary\n",
    "            if not filtered_df.empty:\n",
    "                if la not in la_data_dict:\n",
    "                    la_data_dict[la] = filtered_df\n",
    "                else:\n",
    "                    la_data_dict[la] = pd.concat([la_data_dict[la], filtered_df])\n",
    "\n",
    "# Save the data in the dictionary to CSV files\n",
    "new_path = 'D:\\\\PycharmProjects\\\\minewaters_new\\\\cluster'\n",
    "for la, data in la_data_dict.items():\n",
    "    new_csv_path = os.path.join(new_path, f'{la}.csv')\n",
    "    data.to_csv(new_csv_path, index=False)\n",
    "    print(f'File saved: {new_csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Read the data\n",
    "all_data = pd.read_csv('D:\\\\PycharmProjects\\\\minewaters_new\\\\convert\\\\All_Station_Data.csv', low_memory=False)\n",
    "\n",
    "# Remove rows where local_authority is blank or 'UNKNOWN'\n",
    "all_data = all_data[all_data['local_authority'].str.strip().notna() & (all_data['local_authority'] != 'UNKNOWN')]\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Group by local_authority\n",
    "grouped = all_data.groupby('local_authority')\n",
    "\n",
    "# Generate a unique color for each local_authority\n",
    "num_colors = len(grouped)\n",
    "colors = cm.get_cmap('hsv', num_colors) \n",
    "\n",
    "# Calculate and plot the convex hull for each local_authority\n",
    "for i, (local_auth, group) in enumerate(grouped):\n",
    "    try:\n",
    "        # Calculate the convex hull\n",
    "        hull = ConvexHull(group[['easting', 'northing']])\n",
    "\n",
    "        # Generate color\n",
    "        color = colors(i / num_colors)\n",
    "\n",
    "        # Plot stations\n",
    "        plt.scatter(group['easting'], group['northing'], alpha=0.7, label=f'{local_auth.strip()} stations', color=color)\n",
    "\n",
    "        # Plot the convex hull boundary\n",
    "        for simplex in hull.simplices:\n",
    "            points = group.iloc[simplex][['easting', 'northing']].values\n",
    "            plt.plot([points[0, 0], points[1, 0]], [points[0, 1], points[1, 1]], color=color, linewidth=1)\n",
    "\n",
    "        # Close the convex hull boundary\n",
    "        for simplex in hull.simplices:\n",
    "            points = group.iloc[simplex][['easting', 'northing']].values\n",
    "            # Add last segment to close the polygon\n",
    "            plt.plot([points[-1, 0], points[0, 0]], [points[-1, 1], points[0, 1]], color=color, linewidth=1)\n",
    "\n",
    "    except RuntimeError as e:  # Catch RuntimeError to handle QhullError\n",
    "        print(f\"Error occurred while processing {local_auth}: {e}\")\n",
    "\n",
    "# Set legend and adjust its position\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1)) \n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title('Convex Hulls of All Local Authorities')\n",
    "plt.xlabel('Easting')\n",
    "plt.ylabel('Northing')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('D:\\\\PycharmProjects\\\\minewaters_new\\\\distancesS71567.csv', low_memory=False)\n",
    "\n",
    "# Ensure 'sampling_datetime' column is in datetime format\n",
    "df['sampling_datetime'] = pd.to_datetime(df['sampling_datetime'])\n",
    "\n",
    "# Specify the parameters to analyze\n",
    "parameter_names = ['Solids, Suspended at 105 C','Temperature of Water','Phosphate :- {TIP}','pH','pH : In Situ','Oxygen, Dissolved as O2','Oxygen, Dissolved, % Saturation','Orthophosphate, reactive as P','Nitrogen, Total Oxidised as N','Nitrite as N','Discharge occurrence : In Situ','Ammoniacal Nitrogen as N','Copper','Zinc','Copper, Dissolved','Chemical Oxygen Demand :- {COD}', 'Conductivity at 25 C', 'Conductivity at 20 C']\n",
    "\n",
    "# Create a color map\n",
    "cmap = plt.get_cmap('nipy_spectral')\n",
    "\n",
    "# Iterate over each parameter name\n",
    "for parameter in parameter_names:\n",
    "    # Filter rows for the current parameter name\n",
    "    df_parameter = df[df['parameter_name'] == parameter]\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Get all stations and distances\n",
    "    stations_distance = df_parameter[['station_number', 'distance']].drop_duplicates()\n",
    "    stations_distance = stations_distance.sort_values(by='distance')\n",
    "\n",
    "    # Assign different colors to each station\n",
    "    colors = cmap(np.linspace(0, 1, len(stations_distance)))\n",
    "\n",
    "    # Store legend labels and corresponding colors\n",
    "    handles = []\n",
    "\n",
    "    # Iterate over each station's group and plot its values\n",
    "    for color, (station, group) in zip(colors, stations_distance.groupby('station_number')):\n",
    "        group_sorted = df_parameter[df_parameter['station_number'] == station].sort_values(by='sampling_datetime')\n",
    "        line, = ax.plot(group_sorted['sampling_datetime'], group_sorted['sample_value'],\n",
    "                        label=f'Station {station} - Distance: {group[\"distance\"].iloc[0]:.2f}',\n",
    "                        color=color)\n",
    "        handles.append(line)\n",
    "\n",
    "    # Set the chart title and labels\n",
    "    ax.set_title(f'{parameter} Over Time for All Stations')\n",
    "    ax.set_xlabel('Sampling Datetime')\n",
    "    ax.set_ylabel(parameter)\n",
    "\n",
    "    # Show grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Sort the legend by distance\n",
    "    sorted_labels = sorted(handles, key=lambda h: float(h.get_label().split('Distance: ')[1].split(' ')[0]))\n",
    "    ax.legend(handles=sorted_labels, title='Stations (Distance)')\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
